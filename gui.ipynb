{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet18(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_layer(64, 2, stride=1)\n",
    "        self.layer2 = self._make_layer(128, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(256, 2, stride=2)\n",
    "        self.layer4 = self._make_layer(512, 2, stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, out_channels, blocks, stride):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channels != out_channels:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(BasicBlock(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(BasicBlock(out_channels, out_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model = ResNet18(num_classes=10)\n",
    "model.load_state_dict(torch.load(\"model.pth\", weights_only=True, map_location=torch.device('cpu')))\n",
    "model.eval()  # 切换到评估模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0489, -7.1481, -3.3034,  1.5893, -3.4346,  0.1859, -1.8412, -6.1383,\n",
      "          6.0334, -4.4487]])\n",
      "tensor([[-0.0489, -7.1481, -3.3034,  1.5893, -3.4346,  0.1859, -1.8412, -6.1383,\n",
      "          6.0334, -4.4487]])\n",
      "tensor([[ -7.2414, -14.1827,  -4.6415,   8.3984,  -2.7615,   9.0379,  -2.3469,\n",
      "          -2.7946,  -6.9362,  -9.6751]])\n",
      "tensor([[ -5.5202, -11.9724,  -5.8071,  10.1513,  -3.0799,   4.5606,  -4.0857,\n",
      "          -0.9027,  -5.5029,  -7.5087]])\n",
      "tensor([[ -6.7101, -16.4843,  -1.9581,   7.2758,  -3.8832,   7.7009,  -2.6581,\n",
      "          -0.9913,  -6.6308, -10.2650]])\n",
      "tensor([[ -6.0731, -13.7109,  -3.0840,   5.9586,  -0.5995,   4.8360,  -1.7917,\n",
      "          -2.3065,  -2.2844,  -8.6470]])\n",
      "tensor([[-0.4554, -0.3091, -1.6996,  2.6447, -4.7809, -3.7305,  1.7036, -5.5571,\n",
      "         -4.1814, -4.4909]])\n",
      "tensor([[-0.4554, -0.3091, -1.6996,  2.6447, -4.7809, -3.7305,  1.7036, -5.5571,\n",
      "         -4.1814, -4.4909]])\n",
      "tensor([[-2.8292,  8.3108, -8.6788,  1.0576, -7.5986, -3.0590, -4.0296, -3.4436,\n",
      "         -2.5575, -1.7488]])\n",
      "tensor([[-0.5549, -2.2532, -4.5979, -2.6669, -1.0822, -3.2352, -2.7405, -4.5797,\n",
      "          2.8413, -0.6408]])\n",
      "tensor([[-0.7643,  1.7038, -4.3956, -2.7907, -5.2056, -5.0150, -5.8403, -5.0349,\n",
      "         -2.1854,  5.6797]])\n",
      "tensor([[-0.7643,  1.7038, -4.3956, -2.7907, -5.2056, -5.0150, -5.8403, -5.0349,\n",
      "         -2.1854,  5.6797]])\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageDraw, ImageOps\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import pyperclip\n",
    "import io\n",
    "from PIL import Image, ImageTk, ImageGrab\n",
    "\n",
    "map_word = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "class PaintApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"GUI\")\n",
    "\n",
    "        self.main_frame = tk.Frame(root)\n",
    "        self.main_frame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        self.canvas = tk.Canvas(self.main_frame, bg=\"white\", width=140, height=140)\n",
    "        self.canvas.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "\n",
    "        self.sidebar = tk.Frame(self.main_frame, width=200, bg=\"#f0f0f0\")\n",
    "        self.sidebar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "\n",
    "        self.label = tk.Label(self.sidebar, text=\"预测值为0\", bg=\"#f0f0f0\", font=(\"Arial\", 14))\n",
    "        self.label.pack(pady=20)\n",
    "\n",
    "        self.eval_button = tk.Button(self.sidebar, text=\"推理\", command=self.forward)\n",
    "        self.eval_button.pack(pady=10)\n",
    "\n",
    "        self.paste_button = tk.Button(self.sidebar, text=\"粘贴\", command=self.paste)\n",
    "        self.paste_button.pack(pady=10)\n",
    "\n",
    "        self.clear_button = tk.Button(self.sidebar, text=\"清除\", command=self.clear)\n",
    "        self.clear_button.pack(pady=10)\n",
    "\n",
    "        self.image = Image.new(\"RGB\", (140, 140), \"white\")\n",
    "        self.draw = ImageDraw.Draw(self.image)\n",
    "\n",
    "    def get_clipboard_image(self):\n",
    "        try:\n",
    "            clipboard_data = pyperclip.paste()\n",
    "            \n",
    "            if clipboard_data.startswith(\"data:image/\"):\n",
    "                image_data = clipboard_data.split(\",\")[1]\n",
    "                image_stream = io.BytesIO(base64.b64decode(image_data))\n",
    "                image = Image.open(image_stream)\n",
    "            else:\n",
    "                image = ImageGrab.grabclipboard()\n",
    "            \n",
    "            if image is None:\n",
    "                raise ValueError(\"剪切板中没有图像\")\n",
    "            \n",
    "            return image\n",
    "        except Exception as e:\n",
    "            print(f\"获取剪切板图像失败: {e}\")\n",
    "            return None\n",
    "\n",
    "    def paste(self, event=None):\n",
    "        self.image = self.get_clipboard_image()\n",
    "        if self.image:\n",
    "            photo_image = ImageTk.PhotoImage(self.image.resize((140, 140)))\n",
    "            self.canvas.create_image(0, 0, anchor=tk.NW, image=photo_image)\n",
    "            self.canvas.image = photo_image\n",
    "\n",
    "    def forward(self, event=None):\n",
    "        resized_image = self.image.resize((32, 32))\n",
    "        \n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0], std=[1])\n",
    "        ])\n",
    "        tensor_image = transform(resized_image)\n",
    "        \n",
    "        outputs = model(tensor_image.unsqueeze(0))\n",
    "        print(outputs.data)\n",
    "        _, predicted = torch.max(outputs.data, dim=1)\n",
    "        self.label.config(text=f\"预测值为{map_word[int(predicted)]}\")\n",
    "    def clear(self):\n",
    "        self.canvas.delete(\"all\")\n",
    "\n",
    "        self.image = Image.new(\"RGB\", (140, 140), \"white\")\n",
    "        self.draw = ImageDraw.Draw(self.image)\n",
    "\n",
    "        self.last_x, self.last_y = None, None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = PaintApp(root)\n",
    "    root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
